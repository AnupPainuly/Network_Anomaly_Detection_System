{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Files\n",
    "\n",
    "To run this program, you need an \"all_data.csv\" file. The \"all_data.csv\" file should be located in the same directory as the program.\n",
    "\n",
    "## Program Purpose\n",
    "\n",
    "The purpose of this program is to apply various machine learning algorithms to a dataset and observe their performance. The algorithms used in this program are:\n",
    "\n",
    "- Naive Bayes\n",
    "- QDA (Quadratic Discriminant Analysis)\n",
    "- Random Forest\n",
    "- ID3 (Iterative Dichotomiser 3)\n",
    "- AdaBoost\n",
    "- MLP (Multi-Layer Perceptron)\n",
    "- Nearest Neighbors\n",
    "\n",
    "The program's output includes the following information for each algorithm:\n",
    "\n",
    "- File name\n",
    "- Machine learning algorithm name\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Time taken\n",
    "\n",
    "Additionally, the program will generate a CSV file containing the results and a folder containing graphics.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "Some portions of the code used for calculations and graphing have been adapted from the [scikit-learn website](http://scikit-learn.org).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "          \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test saving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File            ML algorithm     accuracy     Precision    Recall       F1-score     Time         roc_auc     \n",
      "66825/66825 [==============================] - 225s 3ms/step - loss: 10197677375488.0000\n",
      "16707/16707 [==============================] - 27s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 95\u001b[0m\n\u001b[1;32m     91\u001b[0m predict \u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m f_1\u001b[38;5;241m=\u001b[39m\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m pr\u001b[38;5;241m=\u001b[39mprecision_score(y_test, predict, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m rc\u001b[38;5;241m=\u001b[39mrecall_score(y_test, predict, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/lang/python/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[1;32m   1012\u001b[0m     y_true,\n\u001b[1;32m   1013\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lang/python/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[1;32m   1159\u001b[0m     y_true,\n\u001b[1;32m   1160\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m ):\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/lang/python/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/lang/python/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/lang/python/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "\n",
    "result=\"./results/results_3.csv\" #a CSV file is named in which the results are saved.\n",
    "csv_files=[\"all_data.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
    "path=\"\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "def folder(f_name): #this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_3/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "ml_list={\n",
    "\"Naive Bayes\":GaussianNB(),\n",
    "\"QDA\":QDA(),\n",
    "\"XGB\":XGBClassifier(n_estimators=100, learning_rate=0.01, objective='binary:logistic'),\n",
    "\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=100, max_features=2, n_jobs=-1),\n",
    "\"AdaBoost\":AdaBoostClassifier(),\n",
    "\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "\"Nearest Neighbors\":KNeighborsClassifier(3, n_jobs=-1)}\n",
    "\n",
    "\n",
    "\n",
    "#list of all columns to be imported\n",
    "# the 7 features with the highest importance weight selected by the file \"04_2_feature_selection_for_attack_files.py\" are used here. (+ Label Feature)\n",
    "\n",
    "features={\"all_data\":[\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
    "     \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\",\"Label\"]}\n",
    "\n",
    "seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#a CSV file is created to save the results obtained.\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "best_model = {\n",
    "    'algorithm': None,\n",
    "    'roc_auc': 0.0,  # Initialize with a low value\n",
    "    'model': None,    # Store the trained model object\n",
    "}\n",
    "\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    print ('%-15s %-15s  %-12s %-12s %-12s %-12s %-12s %-12s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\", \"roc_auc\"))# print output header   \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        roc_auc = []\n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second=time.time()#time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "            \n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "            \n",
    "            y_scores = clf.predict_proba(X_test)[:, 1]  # Use predicted probabilities for positive class\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "            roc_auc.append(auc(fpr, tpr))\n",
    "            \n",
    "        # Plot ROC curve\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % np.mean(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic - ' + str(ii))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "        cm = confusion_matrix(y_test, predict)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"BENIGN\", \"Attack\"], yticklabels=[\"BENIGN\", \"Attack\"])\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(f\"Confusion Matrix - {ii}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "        print ('%-15s %-15s  %-12s %-12s %-12s %-12s %-12s %-12s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4)),str(round(np.mean(roc_auc),4))))#the result of the ten repetitions is printed on the screen.\n",
    "        if np.mean(roc_auc) > best_model['roc_auc']:\n",
    "            best_model['algorithm'] = ii\n",
    "            best_model['roc_auc'] = np.mean(roc_auc)\n",
    "            best_model['model'] = clf\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "        \n",
    "if best_model['model'] is not None:\n",
    "    best_model_filename = 'best_model.pkl'\n",
    "    with open(best_model_filename, 'wb') as model_file:\n",
    "        pickle.dump(best_model['model'], model_file)\n",
    "    print(f'Best model ({best_model[\"algorithm\"]}) saved as {best_model_filename}')\n",
    "else:\n",
    "    print('No best model found.')\n",
    "\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
       "       'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
       "       'Total Fwd Packets', 'Total Backward Packets',\n",
       "       'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
       "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
       "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
       "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
       "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
       "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
       "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
       "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
       "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
       "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
       "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
       "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
       "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
       "       'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
       "       'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n",
       "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
       "       'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
       "       'Idle Std', 'Idle Max', 'Idle Min', 'Label', 'External IP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106194</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>773</td>\n",
       "      <td>148.0</td>\n",
       "      <td>85.44784</td>\n",
       "      <td>54961.659690</td>\n",
       "      <td>47.0</td>\n",
       "      <td>95825.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.020815</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2672997 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bwd Packet Length Std  Flow Bytes/s  Total Length of Fwd Packets  \\\n",
       "0                          0.0       3000000                         12.0   \n",
       "1                          0.0      12000000                         12.0   \n",
       "2                          0.0      12000000                         12.0   \n",
       "3                          0.0      12000000                         12.0   \n",
       "4                          0.0       4000000                         12.0   \n",
       "...                        ...           ...                          ...   \n",
       "2672992                    0.0             0                          0.0   \n",
       "2672993                    0.0        106194                         12.0   \n",
       "2672994                    0.0             0                          0.0   \n",
       "2672995                    0.0           773                        148.0   \n",
       "2672996                    0.0             0                          0.0   \n",
       "\n",
       "         Fwd Packet Length Std  Flow IAT Std  Flow IAT Min  Fwd IAT Total  \\\n",
       "0                      0.00000      0.000000           4.0            4.0   \n",
       "1                      0.00000      0.000000           1.0            1.0   \n",
       "2                      0.00000      0.000000           1.0            1.0   \n",
       "3                      0.00000      0.000000           1.0            1.0   \n",
       "4                      0.00000      0.000000           3.0            3.0   \n",
       "...                        ...           ...           ...            ...   \n",
       "2672992                0.00000      7.778175          37.0            0.0   \n",
       "2672993                0.00000      0.000000         113.0          113.0   \n",
       "2672994                0.00000      0.000000         115.0            0.0   \n",
       "2672995               85.44784  54961.659690          47.0        95825.0   \n",
       "2672996                0.00000     12.020815          32.0            0.0   \n",
       "\n",
       "          Label  \n",
       "0        BENIGN  \n",
       "1        BENIGN  \n",
       "2        BENIGN  \n",
       "3        BENIGN  \n",
       "4        BENIGN  \n",
       "...         ...  \n",
       "2672992  BENIGN  \n",
       "2672993  BENIGN  \n",
       "2672994  BENIGN  \n",
       "2672995  BENIGN  \n",
       "2672996  BENIGN  \n",
       "\n",
       "[2672997 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\", \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\", 'Label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "model_path = '/home/darkstar/git_repos/intrusion/front_end/model/model.pkl'  # Replace with the actual path to your model file\n",
    "\n",
    "with open(model_path, 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "dat = df[[\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\", \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\"]]\n",
    "\n",
    "\n",
    "    # Example input data for prediction\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(dat)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0, Count: 467125\n",
      "Value: 1, Count: 2205872\n"
     ]
    }
   ],
   "source": [
    "# Find unique values and their counts\n",
    "unique_values, counts = np.unique(predictions, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
